{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import cross_validation\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "from sklearn import ensemble\n",
    "from sklearn import neighbors\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/telco-churn.csv')\n",
    "print (df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = df[\"churn\"].value_counts()\n",
    "sns.barplot(cnt.index, cnt.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt_True = df[\"churn\"][df[\"churn\"] == True]\n",
    "print (\"Churn Percentage = \"+str( (cnt_True.shape[0] / df[\"churn\"].shape[0]) * 100 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn By Area Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"area code\", \"churn\"]).size().unstack().plot(kind='bar', stacked=True, figsize=(5,5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn By Customers with International plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"international plan\", \"churn\"]).size().unstack().plot(kind='bar', stacked=True, figsize=(5,5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Churn By Customers with Voice mail plan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby([\"voice mail plan\", \"churn\"]).size().unstack().plot(kind='bar', stacked=True, figsize=(5,5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle Categorical Cols - Label Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discreet value integer encoder\n",
    "label_encoder = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# State is string and we want discreet integer values\n",
    "df['state'] = label_encoder.fit_transform(df['state'])\n",
    "df['international plan'] = label_encoder.fit_transform(df['international plan'])\n",
    "df['voice mail plan'] = label_encoder.fit_transform(df['voice mail plan'])\n",
    "df['churn'] = label_encoder.fit_transform(df['churn'])\n",
    "\n",
    "#print (df['Voice mail plan'][:4])\n",
    "print (df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tackling imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class count\n",
    "count_class_0, count_class_1 = df.churn.value_counts()\n",
    "\n",
    "# Divide by class\n",
    "df_class_0 = df[df['churn'] == 0]\n",
    "df_class_1 = df[df['churn'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling\n",
    "df_class_0_under = df_class_0.sample(count_class_1)\n",
    "df_under = pd.concat([df_class_0_under, df_class_1], axis=0)\n",
    "\n",
    "print('Random under-sampling:')\n",
    "print(df_under.churn.value_counts())\n",
    "\n",
    "df_under.churn.value_counts().plot(kind='bar', title='Count (churn)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oversampling\n",
    "df_class_1_over = df_class_1.sample(count_class_0, replace=True)\n",
    "df_over = pd.concat([df_class_0, df_class_1_over], axis=0)\n",
    "\n",
    "print('Random over-sampling:')\n",
    "print(df_over.churn.value_counts())\n",
    "\n",
    "df_over.churn.value_counts().plot(kind='bar', title='Count (churn)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_over.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_over['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_over.drop([\"phone number\",\"churn\"], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_over"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the train and validation split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass 1 : Logistic Regression\n",
    "model1 = LogisticRegression()\n",
    "\n",
    "model1.fit(X_train,y_train)\n",
    "y_pred = model1.predict(X_test)\n",
    "print(\"The accuracy score of Logistic Regression model is %s\" %(accuracy_score(y_test,y_pred)))\n",
    "print(\"The fbeta score of Logistic Regression model is %s\" %(fbeta_score(y_test,y_pred,beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DecisionTreeClassifier()\n",
    "model2.fit(X_train,y_train)\n",
    "y_pred = model2.predict(X_test)\n",
    "print(\"The accuracy score of DecisionTreeClassifier model is %s\" %(accuracy_score(y_test,y_pred)))\n",
    "print(\"The fbeta score of DecisionTreeClassifier model is %s\" %(fbeta_score(y_test,y_pred,beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = RandomForestClassifier()\n",
    "model3.fit(X_train,y_train)\n",
    "y_pred = model3.predict(X_test)\n",
    "print(\"The accuracy score of RandomForestClassifier model is %s\" %(accuracy_score(y_test,y_pred)))\n",
    "print(\"The fbeta score of RandomForestClassifier model is %s\" %(fbeta_score(y_test,y_pred,beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 'make_scorer', 'DecisionTreeRegressor', and 'GridSearchCV'\n",
    "from sklearn.metrics import make_scorer,classification_report,confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV,ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(X, y):\n",
    "    \"\"\" Performs grid search over the 'max_depth' parameter for a \n",
    "        decision tree regressor trained on the input data [X, y]. \"\"\"\n",
    "    \n",
    "    # Create cross-validation sets from the training data\n",
    "    cv_sets = ShuffleSplit(n_splits=10, random_state=0, test_size=0.2, train_size=None)\n",
    "\n",
    "    # Create a random forest classifier object\n",
    "    model = RandomForestClassifier()\n",
    "\n",
    "    # Create a dictionary for the parameters 'max_depth',min_samples_split and min_samples_leaf\n",
    "    params = {'max_depth':range(2,12,2),\n",
    "              'min_samples_split':range(2,12,2),\n",
    "              'min_samples_leaf':range(2,12,2)}\n",
    "\n",
    "    # Transform 'performance_metric' into a scoring function using 'make_scorer' \n",
    "    scoring_fnc = make_scorer(fbeta_score, beta=0.5)\n",
    "\n",
    "    # Create the grid search cv object --> GridSearchCV()\n",
    "    grid = GridSearchCV(model,params,scoring_fnc,cv=cv_sets)\n",
    "\n",
    "    # Fit the grid search object to the data to compute the optimal model\n",
    "    grid = grid.fit(X, y)\n",
    "\n",
    "    # Return the optimal model after fitting the data\n",
    "    return grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the training data to the model using grid search\n",
    "reg = fit_model(X_train, y_train)\n",
    "reg.score\n",
    "\n",
    "# Produce the values for 'max_depth',min_samples_split and min_samples_leaf\n",
    "print(\"Parameter 'max_depth' is {} for the optimal model.\".format(reg.get_params()['max_depth']))\n",
    "print(\"Parameter 'min_samples_split' is {} for the optimal model.\".format(reg.get_params()['min_samples_split']))\n",
    "print(\"Parameter 'min_samples_leaf' is {} for the optimal model.\".format(reg.get_params()['min_samples_leaf']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying best hyperparameter values to RandomForestClassfier\n",
    "rf_clf = RandomForestClassifier(max_depth=10,min_samples_split=6,min_samples_leaf=2)\n",
    "rf_clf.fit(X_train,y_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "print(\"The accuracy score of hypertuned RandomForestClassifier model is %s\" %(accuracy_score(y_test,y_pred)))\n",
    "print(\"The fbeta score of hypertuned RandomForestClassifier model is %s\" %(fbeta_score(y_test,y_pred,beta=0.5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exhibiting feature importance\n",
    "features = X.columns\n",
    "importances = rf_clf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
